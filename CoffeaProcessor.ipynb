{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "biblical-massage",
   "metadata": {},
   "source": [
    "# Coffea processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea import hist, util\n",
    "\n",
    "import coffea.processor as processor\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "import awkward as ak\n",
    "import uproot\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-cache",
   "metadata": {},
   "source": [
    "The code below introduces some basic concepts for writing code using Coffea.\n",
    "\n",
    "There are three primary pieces to the Coffea code:\n",
    "\n",
    "The processor, which contains all of the analysis cuts and fills the histogram in the process function.\n",
    "The second cell defines the files we want to run over and then runs the code using run_uproot_job.\n",
    "After we run the processor, we can then plot any of the histograms we have generated.\n",
    "To test any changes you make to the histograms, you will have to rerun each of the three cells below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuonSelector(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        # In the initializer, any of the outputs you would like to produce are defined (ex. histograms)\n",
    "\n",
    "        # Coffea histograms are defined in the same way as in the previous exercise\n",
    "        # define a list of axes first\n",
    "\n",
    "        #Declare an axis for the dataset\n",
    "        dataset_axis = hist.Cat(\"dataset\",\"Dataset\")\n",
    "        \n",
    "        #Declare an axis for the muon pt\n",
    "        muon_pt_axis = hist.Bin(\"pt\",\"$p_{T}$ [GeV]\", 40, 0, 200)\n",
    "        \n",
    "        #Define the accumulator object, a dictionary storing all of the histograms and counters \n",
    "        #that we will fill later in the process function\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            'muon_pt': hist.Hist(\"Counts\", dataset_axis, muon_pt_axis),\n",
    "        }\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    \n",
    "\n",
    "    # The process method is where the heart of the analysis is.  \n",
    "    # This is where all of the selections are done and the histograms get filled \n",
    "    #  (things you did in notebook cells before will be done here instead)\n",
    "    def process(self, events):\n",
    "        ### The process function is where most of the work happens. As we'll see below, this is\n",
    "        ### where the main analysis work happens (object cuts, event selections, filling histograms). \n",
    "        \n",
    "        ## This gets us the accumulator dictionary we defined in init\n",
    "        output = self.accumulator.identity()\n",
    "\n",
    "        ## To access variables from the ntuples, use the \"events\" object\n",
    "        ## The dataset name is part of events.metadata\n",
    "        dataset = events.metadata['dataset']\n",
    "\n",
    "        ## The coffea NanoEventSchema packages all muon variables (columns) into the events.Muon object\n",
    "        ## Each variable can be accessed using muons.key_name\n",
    "        muons = events.Muon        \n",
    "        \n",
    "        ######\n",
    "        # Select muons with pt >30, eta < 2.4, tight ID, and relIso < 0.15\n",
    "        muonSelectTight = ((muons.pt>30) &\n",
    "                           (abs(muons.eta)<2.4) &\n",
    "                           (muons.tightId) &\n",
    "                           (muons.pfRelIso04_all < 0.15)\n",
    "                          )\n",
    "\n",
    "        # Apply the selection to muons using the array[mask] syntax. \n",
    "        # tightMuons only includes the muons that pass the tight selection we defined\n",
    "        tightMuons = muons[muonSelectTight]\n",
    "        \n",
    "        \n",
    "        # Select events with exactly one tight muon. \n",
    "        eventSelection = (ak.num(tightMuons)==1)\n",
    "\n",
    "        # Fill the muon_pt histogram using the tightMuons in events that pass our selection \n",
    "        # Note that ak.flatten() is required when filling a histogram to remove the jaggedness\n",
    "        output['muon_pt'].fill(dataset=dataset,\n",
    "                              pt=ak.flatten(tightMuons[eventSelection].pt))\n",
    "\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define files to run over\n",
    "skimDir=\"/udrive/staff/dnoonan/Skims\"\n",
    "fileset = {\"TTGamma\":[f\"{skimDir}/TTGamma_SingleLept_2016_skim.root\"],\n",
    "           \"TTbar\":[f\"{skimDir}/TTbarPowheg_Semilept_2016_skim_1of10.root\",\n",
    "                    f\"{skimDir}/TTbarPowheg_Semilept_2016_skim_2of10.root\"],\n",
    "           \"WGamma\":[f\"{skimDir}/WGamma_2016_skim.root\"],\n",
    "          }\n",
    "\n",
    "\n",
    "#the NanoAODSchema needs to be adjusted, to remove cross references to FSRPhotons\n",
    "class SkimmedSchema(NanoAODSchema):\n",
    "    def __init__(self, base_form):\n",
    "        base_form[\"contents\"].pop(\"Muon_fsrPhotonIdx\", None)\n",
    "        super().__init__(base_form)\n",
    "\n",
    "#Run Coffea code using uproot\n",
    "output = processor.run_uproot_job(\n",
    "    fileset,  #dictionary of datasets to run on, defined earlier in this cell\n",
    "    \"Events\", #Name of the TTree you will be opening\n",
    "    MuonSelector(),  #Coffea processor you defined\n",
    "    processor.futures_executor,\n",
    "    executor_args={\"schema\": SkimmedSchema,'workers': 4},  ## workers = 2, parallelize jobs, running 2 at once\n",
    "    chunksize=100000, #in each chunk, use 50k events\n",
    "#    maxchunks=3, #limit to using only 3 chunks for each dataset (useful for testing purposes)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.plot1d(output['muon_pt'],overlay='dataset',stack=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-grade",
   "metadata": {},
   "source": [
    "### Histogram Scaling\n",
    "\n",
    "When comparing a Monte-Carlo to Data, we need to scale the MC to the number of events we expect to see in a given amount of data.\n",
    "\n",
    "$\\text{N}_\\text{expected} = \\sigma \\cdot L$\n",
    "\n",
    " - $\\text{N}_\\text{expected}$ = Number of events expected\n",
    " - $\\sigma$ = cross section of a specific process\n",
    " - $L$ = integrated luminosity of data\n",
    " \n",
    "In MC, we often generate far more events than we expect (for better statistical uncertainties), so we need rescale the MC distributions.  This is done by reweighting each MC dataset, where the weight applied is the ratio of the number of events expected to the number of events produced in the MC ($\\text{N}_{MC}$)\n",
    "\n",
    "$\\Huge w = \\frac{\\text{N}_\\text{MC}}{\\text{N}_\\text{expected}} = \\frac{\\text{N}_\\text{MC}}{\\sigma \\cdot L}$\n",
    "\n",
    "The number of events in MC and the cross section will change for each dataset\n",
    "\n",
    "#### Cross sections\n",
    "| Process | Cross Section (pb) |\n",
    "| :--- | :---: |\n",
    "| TTGamma (single lepton) | 7.509 |\n",
    "| TTbar (single lepton) | 380.095 |\n",
    "| WGamma | 489 |\n",
    "\n",
    "#### Number of events\n",
    "\n",
    "The $\\text{N}_\\text{MC}$ value should be the total number of \n",
    "Normally, in NanoAOD, you could keep track of the number of events are in the files that you process (tallying the total number of events in each sample, across all chunks processed).\n",
    "\n",
    "However, since we are running on skims of the full MC sets, some of the events have already been removed.  However, in this case, we get the \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the code below uses uproot to open a histogram in the root file, used to track the total\n",
    "#  number of events processed while producing the skim\n",
    "\n",
    "nEvents = {}\n",
    "for d in fileset:\n",
    "    if not d in nEvents:\n",
    "        nEvents[d] = 0\n",
    "    for fName in fileset[d]:\n",
    "        with uproot.open(fName)['hEvents'] as hist:\n",
    "            nEvents[d] += hist.values()[0] + hist.values()[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-welding",
   "metadata": {},
   "source": [
    "### Calculate weights\n",
    "\n",
    "Make a dictionary, containing the weights to apply for each dataset in fileset\n",
    "The dictionary should have the same key names as are in fileset, since these are what get used as the 'dataset' in the histogram axis.\n",
    "\n",
    "The actual CMS data you are using corresponds to an integrated luminosity $L = X.XX \\text{fb}^{-1}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## To Do\n",
    "## Make new dictionary named weights, containing the luminosity and cross section based weights for each sample\n",
    "###############\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop over objects in the output, and scale them to the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-aberdeen",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "### Z-boson selector\n",
    "\n",
    "In this step, we're going to try to find events from a Z boson.\n",
    "\n",
    "You are going to implement a selection looking for events with exactly two leptons that have opposite charge.  These leptons should pass the same 'tight' selections used in the previous notebook for selecting electrons and muons.\n",
    "\n",
    "We are looking for events that have exactly two leptons of one flavor (either two electrons, or two muons) and where the two leptons have opposite charge (one electron and one positron, or one muon and one antimuon).\n",
    "\n",
    "Then, make the following plots:\n",
    " - $p_T$ of the leading muon in the event\n",
    " - $p_T$ of the leading electron in the event\n",
    " - Mass of the combination of the two leptons\n",
    " - Difference between the two leptons in eta\n",
    " - Difference between the two leptons in phi\n",
    " - Difference between the two leptons in R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zselector(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        ### This function is where the histograms are defined and any other initialization happens\n",
    "        \n",
    "        ### Muon pt\n",
    "        #Declare an axis for the dataset\n",
    "        dataset_axis = hist.Cat(\"dataset\",\"Dataset\")\n",
    "        \n",
    "        #Declare an axis for the muon pt\n",
    "        muon_pt_axis = hist.Bin(\"pt\",\"$p_{T}$ [GeV]\", 40, 0, 200)\n",
    "\n",
    "        #Define the accumulator object, a dictionary storing all of the histograms and counters \n",
    "        #that we will fill later in the process function\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            'muon_pt': hist.Hist(\"Counts\", dataset_axis, muon_pt_axis),\n",
    "        }\n",
    "        )\n",
    "\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    def process(self, events):\n",
    "        ### The process function is where most of the work happens. As we'll see below, this is\n",
    "        ### where the main analysis work happens (object cuts, event selections, filling histograms). \n",
    "        \n",
    "        ## This gets us the accumulator dictionary we defined in init\n",
    "        output = self.accumulator.identity()\n",
    "\n",
    "        ## To access variables from the ntuples, use the \"events\" object\n",
    "        ## The dataset name is part of events.metadata\n",
    "        dataset = events.metadata['dataset']\n",
    "\n",
    "        # Fill the muon_pt histogram using the tightMuons in events that pass our selection \n",
    "        # Note that ak.flatten() is required when filling a histogram to remove the jaggedness\n",
    "        output['muon_pt'].fill(dataset=dataset,\n",
    "                              pt=ak.flatten(tightMuons[eventSelection].pt))\n",
    "        \n",
    "        ######\n",
    "        ### Step 4. Fill the ele_pt histogram you defined earlier\n",
    "        ###### \n",
    "        \n",
    "        \n",
    "        ######\n",
    "        \n",
    "        \n",
    "        \n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttgenv",
   "language": "python",
   "name": "ttgenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
